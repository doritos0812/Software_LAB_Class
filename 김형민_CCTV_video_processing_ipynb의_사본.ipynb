{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "김형민_CCTV_video_processing.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/doritos0812/Software_LAB_Class/blob/main/%EA%B9%80%ED%98%95%EB%AF%BC_CCTV_video_processing_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fNa3bQYIowo"
      },
      "source": [
        "# CCTV video processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvFGLD8OI15C"
      },
      "source": [
        "__<div style=\"text-align: right\"> EE370: Software lab, Kyung Hee University. </div>__\n",
        "_<div style=\"text-align: right\"> Jong-Han Kim (jonghank@khu.ac.kr) </div>_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euOD9tW-c8R1"
      },
      "source": [
        "In this section, we will use OpenCV, one of the most popularly used image and video processing libraries, for extracting useful information form an RGB video clip obtained from a CCTV system.\n",
        "\n",
        "Throught this exercise, you may take full advantages from using the OpenCV library (https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_tutorials.html) for whatever operation you may have to do.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqArZnGUIowq"
      },
      "source": [
        "We will access data files which are uploaded on the Google drive. In order to do this, we will have to mount the Goodle drive first. \n",
        "\n",
        "1) Run the following cell. Then you will be presented with a link and will be asked to enter your authorization code.\n",
        "\n",
        "2) Click on the link to log in again with your KHU account, which you are working with. Then you will be presented with the authorization code.\n",
        "\n",
        "3) Copy the authorization code, and paste it into the blank.\n",
        "\n",
        "> _Note that this step is necessary ONLY when you work on Google Colab environment._\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCDg3bWHMwgv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "35083db6-117a-4159-b63a-db68f0b4952d"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks/ee370')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d83Nsr_Q8I1u"
      },
      "source": [
        "The following will load a video clip `vtest.avi` from your local directory. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cds69hJT8ITM"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "cap = cv2.VideoCapture('vtest.avi')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "en4J0GVMCDbB"
      },
      "source": [
        "For your information, the frame size and the frame rate can be obtained from the following."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aS_Bj3S6AuKy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c9f1cd9f-6173-4ab5-80c1-81ceb0502ecf"
      },
      "source": [
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "print (width, height, fps)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "768 576 10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVH2NKcsVrs5"
      },
      "source": [
        "Now your job is to detect moving persons wearing a red clothing. For example, for every frame from the clip like below,\n",
        "\n",
        "<center>\n",
        "<img src=\"https://jonghank.github.io/ee370/files/cctv1.jpg\" width=\"600\">\n",
        "</center>\n",
        "\n",
        "you have to highlight moving persons with a red clothing\n",
        "\n",
        "<center>\n",
        "<img src=\"https://jonghank.github.io/ee370/files/cctv2.jpg\" width=\"600\">\n",
        "</center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgdL9o7wFd8p"
      },
      "source": [
        "You may need to do the followings.\n",
        "\n",
        "- Look around the whole pages (https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_tutorials.html).\n",
        "\n",
        "- Separate the foreground (moving persons) from the background, for detecting moving objects (https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_video/py_bg_subtraction/py_bg_subtraction.html).\n",
        "\n",
        "- Convert the frames to HSV scale, and carefully define the range of red colors in HSV scale, so that the defined bounds easily detect the red clothings.\n",
        "to get masks for detecting red-ish pixels (https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_colorspaces/py_colorspaces.html). \n",
        "\n",
        "- Download and play the processed `output.avi` to check if everything was done as what you intended."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RBJ-_iXDLSI"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "cap = cv2.VideoCapture('vtest.avi')\n",
        "fgbg = cv2.bgsegm.createBackgroundSubtractorMOG()\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
        "out = cv2.VideoWriter('output.avi',fourcc, 10.0, (768,576))\n",
        "while(1):\n",
        "  ret, frame = cap.read()    \n",
        "  if ret==True:   \n",
        "    hsv=cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
        "    lower_red = np.array([160,150,80])\n",
        "    upper_red=np.array([180,255,255])\n",
        "    fgmask=fgbg.apply(hsv)  \n",
        "    mask=cv2.inRange(hsv,lower_red,upper_red)\n",
        "    res=cv2.bitwise_and(frame,frame, mask=mask)\n",
        "\n",
        "    out.write(res)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "      break\n",
        "  else:\n",
        "    break\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}